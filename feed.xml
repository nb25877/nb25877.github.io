<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>Nikunj Bhalotia E-Portfolio</title>
    <link href="https://nb25877.github.io/feed.xml" rel="self" />
    <link href="https://nb25877.github.io" />
    <updated>2026-01-30T10:10:46+04:00</updated>
    <author>
        <name>Nikunj Bhalotia</name>
    </author>
    <id>https://nb25877.github.io</id>

    <entry>
        <title>DR Solutions Design and Review</title>
        <author>
            <name>Nikunj Bhalotia</name>
        </author>
        <link href="https://nb25877.github.io/dr-solutions-design-and-review/"/>
        <id>https://nb25877.github.io/dr-solutions-design-and-review/</id>

        <updated>2026-01-22T15:32:46+04:00</updated>
            <summary type="html">
                <![CDATA[
                    Based on Kumar (2024) and Corbari et al. (2024) 1. What are some of the main vendor lock-in issues the authors identify? How would you mitigate them? According to Kumar (2024), vendor lock-in manifests primarily through Technical and Organizational obstacles. Mitigation Strategies: To mitigate these&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <!-- wp:heading -->
<h2 class="wp-block-heading">Based on Kumar (2024) and Corbari et al. (2024)</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p><strong>1. What are some of the main vendor lock-in issues the authors identify? How would you mitigate them?</strong> According to Kumar (2024), vendor lock-in manifests primarily through <strong>Technical</strong> and <strong>Organizational</strong> obstacles.</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li><strong>Technical Issues:</strong> The use of proprietary APIs and non-standard data formats creates high switching costs. Once an organization integrates deeply with a specific cloud provider’s ecosystem (e.g., using AWS Lambda or proprietary databases), migrating to a different DR provider becomes technically prohibitive due to compatibility issues.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Organizational/Legal Issues:</strong> Restrictive contracts and the lack of interoperability standards further bind organizations to a single vendor.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>Mitigation Strategies:</strong> To mitigate these risks, I would recommend a <strong>Multi-Cloud Strategy</strong> combined with <strong>Containerization</strong> (e.g., Docker/Kubernetes). By abstracting the application layer from the underlying infrastructure, organizations can move workloads between providers with minimal friction. Additionally, enforcing the use of <strong>Open Standards</strong> and avoiding proprietary PaaS (Platform as a Service) features where possible ensures that the DR solution remains portable.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2. What are some security concerns with the modern cloud? How can these be mitigated?</strong> A major security concern in modern cloud environments is the <strong>loss of visibility and control</strong> over the underlying infrastructure. However, a more subtle but critical concern identified by Corbari et al. (2024) is the <strong>complexity of dependencies</strong>. In complex cloud environments, it is difficult to identify exactly which assets are critical to a specific business function. If a DR plan fails to account for a hidden dependency (e.g., an external authentication service), the recovery will fail.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Mitigation Strategies:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li><strong>Mission Thread Analysis (MTA):</strong> I would apply the framework proposed by Corbari et al. (2024) to map the "Mission Relevant Cyber Terrain." This process involves tracing a specific operational thread (e.g., "Process Customer Payment") end-to-end to identify every critical node and link.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Shared Responsibility Awareness:</strong> Organizations must clearly define where the vendor's security responsibility ends and theirs begins, particularly regarding data encryption and access control.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>References</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li>Corbari, G.I., Khatod, N., Popiak, J.F. and Sinclair, P. (2024) ‘Mission Thread Analysis: Establishing a Common Framework’, <em>The Cyber Defense Review</em>, 9(1), pp. 37–54.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Kumar, A. (2024) <em>Cloud Vendor Lock-In: Identify, Strategies and Mitigate</em>. Seminar Paper, Julius-Maximilians-Universität Würzburg.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->
            ]]>
        </content>
    </entry>
    <entry>
        <title>Modelling Social Engineering Threats Based on Aijaz, M. and Nazir, M. (2024)</title>
        <author>
            <name>Nikunj Bhalotia</name>
        </author>
        <link href="https://nb25877.github.io/modelling-social-engineering-threats-based-on-aijaz-m-and-nazir-m-2024/"/>
        <id>https://nb25877.github.io/modelling-social-engineering-threats-based-on-aijaz-m-and-nazir-m-2024/</id>

        <updated>2026-01-22T14:27:29+04:00</updated>
            <summary type="html">
                <![CDATA[
                    1. What are the main challenges in modelling and evaluating the outcomes of Social Engineering Threats (SETs), and how does this study address them? The primary challenge in modelling SETs is the inherent unpredictability of human behavior, which makes rigorous mathematical evaluation difficult. Unlike technical&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <!-- wp:paragraph -->
<p><strong>1. What are the main challenges in modelling and evaluating the outcomes of Social Engineering Threats (SETs), and how does this study address them?</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>The primary challenge in modelling SETs is the inherent unpredictability of human behavior, which makes rigorous mathematical evaluation difficult. Unlike technical exploits, SETs rely on psychological manipulation, which is historically hard to quantify. The study addresses this by structuring SETs not as random events, but as systematic processes involving specific modalities (e.g., email, phone) and persuasion principles (e.g., authority, scarcity). By categorizing these variables, the authors are able to apply Markov Chain models to calculate the probability of an attack moving from one stage to the next.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2. How do persuasion principles and modalities contribute to the success of SETs?</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Persuasion principles (derived from Cialdini’s framework, such as Reciprocity, Commitment, and Social Proof) act as the "exploit code" of a social engineering attack. The study highlights that the success of a SET depends heavily on the pairing of a Modality (the medium, e.g., social media) with the correct Persuasion Principle. Systematically analyzing these pairs is critical because certain combinations yield higher success rates; for example, "Authority" might be more effective via email, while "Liking" works better on social media. Understanding these combinations allows defenders to predict which specific scenarios pose the highest risk.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>3. What role do the Attack Tree Model and Markov Chain Model play in estimating probabilities?</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>The study utilizes a hybrid approach to estimate risk:</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li><strong>Attack Tree Model:</strong> This is used to calculate the <strong>Attack Occurrence Probability (AOP)</strong>. It maps the hierarchical structure of an attack, using frequency data to estimate how likely a specific attack path is to be attempted.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Markov Chain Model:</strong> This is used to calculate the <strong>Attack Success Probability (ASP)</strong>. It models the attack as a sequence of states (e.g., Start &gt; Medium &gt; Persuasion &gt; Compromise). The Markov model calculates the probability of transitioning from one state to the next based on the effectiveness of the chosen persuasion principle.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>4. How can the findings support the development of effective policy frameworks?</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>By quantifying the ASP of specific attacks, organizations can move beyond generic "Security Awareness Training" to targeted interventions. For instance, if the model shows that the "Authority" principle delivered via "Email" has the highest success probability, policies can be adjusted to enforce strict verification for executive requests (e.g., mandatory voice confirmation for wire transfers). This allows resources to be allocated based on mathematical risk rankings rather than anecdotal evidence.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>References</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li>Aijaz, M. and Nazir, M. (2024) ‘Modelling and analysis of social engineering threats using the attack tree and the Markov model’, <em>International Journal of Information Technology</em>, 16(2), pp. 1231–1238. Available at: <a href="https://doi.org/10.1007/s41870-023-01540-z" target="_blank" rel="noreferrer noopener">https://doi.org/10.1007/s41870-023-01540-z</a></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->
            ]]>
        </content>
    </entry>
    <entry>
        <title>Bayesian Risk Update (Think Bayes 2) Based on Downey (2022), Chapters 1 &amp; 2</title>
        <author>
            <name>Nikunj Bhalotia</name>
        </author>
        <link href="https://nb25877.github.io/bayesian-risk-update-think-bayes-2-based-on-downey-2022-chapters-1-andamp-2/"/>
        <id>https://nb25877.github.io/bayesian-risk-update-think-bayes-2-based-on-downey-2022-chapters-1-andamp-2/</id>

        <updated>2026-01-22T13:21:55+04:00</updated>
            <summary type="html">
                <![CDATA[
                    I used Allen Downey’s ThinkBayes2 library to practice Diachronic Bayes, the process of updating a hypothesis (H) based on new data (D). Description: This script adapts the 'Think Bayes' methodology to a security context. It updates the probability of a specific threat (Hypothesis) being active&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <!-- wp:paragraph -->
<p>I used Allen Downey’s <code>ThinkBayes2</code> library to practice <strong>Diachronic Bayes</strong>, the process of updating a hypothesis (H) based on new data (D).</p>
<!-- /wp:paragraph -->
<p> </p>
<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li><strong>The Problem:</strong> I worked through the "Cookie Problem" and "Monty Hall Problem" to understand the mechanics of the formula: P(H|D) = (P(H)P(D|H))/(P(D)).</li>
<!-- /wp:list-item --> <!-- wp:list-item -->
<li><strong>Application to Risk:</strong> I treated the "Prior" (P(H)) as our initial risk assessment (e.g., "There is a 10% chance of a breach"). I then calculated the "Likelihood" (P(D|H)) based on new evidence (e.g., "A firewall log showed 5 failed login attempts").</li>
<!-- /wp:list-item --> <!-- wp:list-item -->
<li><strong>Outcome:</strong> The calculation produced a "Posterior" probability, mathematically demonstrating that risk is dynamic. This highlighted a flaw in traditional "static" risk registers, which often fail to account for real-time threat intelligence.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->
<p> </p>
<!-- wp:paragraph -->
<p>Description: This script adapts the 'Think Bayes' methodology to a security context. It updates the probability of a specific threat (Hypothesis) being active after observing a specific indicator (Evidence).</p>
<!-- /wp:paragraph -->
<p> </p>
<!-- wp:code {"tokenizedLines":[[["IyBBIHNpbXBsaWZpZWQgY2xhc3Mgc3RydWN0dXJlIGJhc2VkIG9uIERvd25leSdzICdQbWYnIChQcm9iYWJpbGl0eSBNYXNzIEZ1bmN0aW9uKQ=="]],[["Y2xhc3MgUmlza0h5cG90aGVzaXM6"]],[["ICAgIGRlZiBfX2luaXRfXyhzZWxmLCBwcmlvcnMpOg=="]],[["ICAgICAgICAiIiI="]],[["ICAgICAgICBwcmlvcnM6IERpY3Rpb25hcnkgb2Yge0h5cG90aGVzaXM6IFByb2JhYmlsaXR5fQ=="]],[["ICAgICAgICBlLmcuLCB7J0hpZ2hfUmlzayc6IDAuMSwgJ0xvd19SaXNrJzogMC45fQ=="]],[["ICAgICAgICAiIiI="]],[["ICAgICAgICBzZWxmLmh5cG90aGVzZXMgPSBwcmlvcnM="]],[[""]],[["ICAgIGRlZiBub3JtYWxpemUoc2VsZik6"]],[["ICAgICAgICAiIiJFbnN1cmVzIGFsbCBwcm9iYWJpbGl0aWVzIHN1bSB0byAxLjAiIiI="]],[["ICAgICAgICB0b3RhbCA9IHN1bShzZWxmLmh5cG90aGVzZXMudmFsdWVzKCkp"]],[["ICAgICAgICBmb3IgaHlwbyBpbiBzZWxmLmh5cG90aGVzZXM6"]],[["ICAgICAgICAgICAgc2VsZi5oeXBvdGhlc2VzW2h5cG9dIC89IHRvdGFs"]],[[""]],[["ICAgIGRlZiB1cGRhdGUoc2VsZiwgZXZpZGVuY2UsIGxpa2VsaWhvb2RzKTo="]],[["ICAgICAgICAiIiI="]],[["ICAgICAgICBCYXllcyBUaGVvcmVtIEFwcGxpY2F0aW9uOiBQKEh8RSkgPSBQKEgpICogUChFfEgpIC8gUChFKQ=="]],[["ICAgICAgICBldmlkZW5jZTogU3RyaW5nIG5hbWUgb2YgdGhlIGV2aWRlbmNlIG9ic2VydmVk"]],[["ICAgICAgICBsaWtlbGlob29kczogRGljdGlvbmFyeSBvZiB7SHlwb3RoZXNpczogUHJvYmFiaWxpdHlfb2ZfRXZpZGVuY2V9"]],[["ICAgICAgICAiIiI="]],[["ICAgICAgICBmb3IgaHlwbyBpbiBzZWxmLmh5cG90aGVzZXM6"]],[["ICAgICAgICAgICAgIyAxLiBHZXQgdGhlIFByaW9yIFAoSCk="]],[["ICAgICAgICAgICAgcHJpb3IgPSBzZWxmLmh5cG90aGVzZXNbaHlwb10="]],[["ICAgICAgICAgICAg"]],[["ICAgICAgICAgICAgIyAyLiBHZXQgdGhlIExpa2VsaWhvb2QgUChFfEgp"]],[["ICAgICAgICAgICAgIyAiSWYgdGhpcyBoeXBvdGhlc2lzIHdlcmUgdHJ1ZSwgaG93IGxpa2VseSBpcyB0aGlzIGV2aWRlbmNlPyI="]],[["ICAgICAgICAgICAgbGlrZWxpaG9vZCA9IGxpa2VsaWhvb2RzW2h5cG9d"]],[["ICAgICAgICAgICAg"]],[["ICAgICAgICAgICAgIyAzLiBDYWxjdWxhdGUgVW4tbm9ybWFsaXplZCBQb3N0ZXJpb3I="]],[["ICAgICAgICAgICAgc2VsZi5oeXBvdGhlc2VzW2h5cG9dID0gcHJpb3IgKiBsaWtlbGlob29k"]],[["ICAgICAgICAgICAg"]],[["ICAgICAgICAjIDQuIE5vcm1hbGl6ZSAoZGl2aWRpbmcgYnkgUChFKSk="]],[["ICAgICAgICBzZWxmLm5vcm1hbGl6ZSgp"]],[[""]],[["IyAtLS0gVVNFIENBU0U6IElOQ0lERU5UIFJFU1BPTlNFIC0tLQ=="]],[["IyBTY2VuYXJpbzogV2Ugc2VlIGEgZmFpbGVkIGxvZ2luLiBJcyBpdCBhIEJydXRlIEZvcmNlIEF0dGFjayBvciBqdXN0IGEgVXNlciBNaXN0YWtlPw=="]],[[""]],[["IyAxLiBFU1RBQkxJU0ggUFJJT1JTIChCYXNlbGluZSBwcm9iYWJpbGl0eSk="]],[["IyBXZSBhc3N1bWUgQnJ1dGUgRm9yY2UgYXR0YWNrcyBhcmUgcmFyZSAoMTAlKSBjb21wYXJlZCB0byBVc2VyIE1pc3Rha2VzICg5MCUp"]],[["cHJpb3JzID0geydCcnV0ZV9Gb3JjZSc6IDAuMSwgJ1VzZXJfTWlzdGFrZSc6IDAuOX0="]],[["cmlza19tb2RlbCA9IFJpc2tIeXBvdGhlc2lzKHByaW9ycyk="]],[[""]],[["cHJpbnQoIi0tLSBQUklPUiBCRUxJRUZTIC0tLSIp"]],[["cHJpbnQocmlza19tb2RlbC5oeXBvdGhlc2VzKQ=="]],[[""]],[["IyAyLiBORVcgRVZJREVOQ0U6IDUgRmFpbGVkIExvZ2lucyBpbiAxIE1pbnV0ZQ=="]],[["IyBMaWtlbGlob29kIFAoRXxIKTo="]],[["IyAtIElmIGl0IElTIGEgQnJ1dGUgRm9yY2UgYXR0YWNrLCA1IGZhaWxzIGluIDEgbWluIGlzIHZlcnkgbGlrZWx5ICg5MCUp"]],[["IyAtIElmIGl0IElTIGEgVXNlciBNaXN0YWtlLCA1IGZhaWxzIGluIDEgbWluIGlzIHJhcmUgKDUlKQ=="]],[["ZXZpZGVuY2VfbGlrZWxpaG9vZHMgPSB7"]],[["ICAgICdCcnV0ZV9Gb3JjZSc6IDAuOTAs"]],[["ICAgICdVc2VyX01pc3Rha2UnOiAwLjA1"]],[["fQ=="]],[[""]],[["IyAzLiBVUERBVEUgQkVMSUVGUw=="]],[["cmlza19tb2RlbC51cGRhdGUoZXZpZGVuY2U9IjVfZmFpbHNfMV9taW4iLCBsaWtlbGlob29kcz1ldmlkZW5jZV9saWtlbGlob29kcyk="]],[[""]],[["cHJpbnQoIlxuLS0tIFBPU1RFUklPUiBCRUxJRUZTIChBZnRlciBFdmlkZW5jZSkgLS0tIik="]],[["Zm9yIGh5cG8sIHByb2IgaW4gcmlza19tb2RlbC5oeXBvdGhlc2VzLml0ZW1zKCk6"]],[["ICAgIHByaW50KGYie2h5cG99OiB7cHJvYjouMiV9Iik="]],[[""]],[["IyBSZXN1bHQ6IFRoZSBwcm9iYWJpbGl0eSBvZiAnQnJ1dGVfRm9yY2UnIHdpbGwganVtcCBzaWduaWZpY2FudGx5"]],[[""]]]} -->
<pre class="wp-block-code"><code># A simplified class structure based on Downey's 'Pmf' (Probability Mass Function)
class RiskHypothesis:
    def __init__(self, priors):
        """
        priors: Dictionary of {Hypothesis: Probability}
        e.g., {'High_Risk': 0.1, 'Low_Risk': 0.9}
        """
        self.hypotheses = priors

    def normalize(self):
        """Ensures all probabilities sum to 1.0"""
        total = sum(self.hypotheses.values())
        for hypo in self.hypotheses:
            self.hypotheses[hypo] /= total

    def update(self, evidence, likelihoods):
        """
        Bayes Theorem Application: P(H|E) = P(H) * P(E|H) / P(E)
        evidence: String name of the evidence observed
        likelihoods: Dictionary of {Hypothesis: Probability_of_Evidence}
        """
        for hypo in self.hypotheses:
            # 1. Get the Prior P(H)
            prior = self.hypotheses[hypo]
            
            # 2. Get the Likelihood P(E|H)
            # "If this hypothesis were true, how likely is this evidence?"
            likelihood = likelihoods[hypo]
            
            # 3. Calculate Un-normalized Posterior
            self.hypotheses[hypo] = prior * likelihood
            
        # 4. Normalize (dividing by P(E))
        self.normalize()

# --- USE CASE: INCIDENT RESPONSE ---
# Scenario: We see a failed login. Is it a Brute Force Attack or just a User Mistake?

# 1. ESTABLISH PRIORS (Baseline probability)
# We assume Brute Force attacks are rare (10%) compared to User Mistakes (90%)
priors = {'Brute_Force': 0.1, 'User_Mistake': 0.9}
risk_model = RiskHypothesis(priors)

print("--- PRIOR BELIEFS ---")
print(risk_model.hypotheses)

# 2. NEW EVIDENCE: 5 Failed Logins in 1 Minute
# Likelihood P(E|H):
# - If it IS a Brute Force attack, 5 fails in 1 min is very likely (90%)
# - If it IS a User Mistake, 5 fails in 1 min is rare (5%)
evidence_likelihoods = {
    'Brute_Force': 0.90,
    'User_Mistake': 0.05
}

# 3. UPDATE BELIEFS
risk_model.update(evidence="5_fails_1_min", likelihoods=evidence_likelihoods)

print("\n--- POSTERIOR BELIEFS (After Evidence) ---")
for hypo, prob in risk_model.hypotheses.items():
    print(f"{hypo}: {prob:.2%}")

# Result: The probability of 'Brute_Force' will jump significantly

</code></pre>
<!-- /wp:code -->
<p> </p>
<!-- wp:paragraph -->
<p><strong>References</strong>:</p>
<!-- /wp:paragraph -->
<p> </p>
<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li>Downey, A. (2022) <em>Think Bayes 2</em>. Available at: <a href="https://allendowney.github.io/ThinkBayes2/" target="_blank" rel="noreferrer noopener">https://allendowney.github.io/ThinkBayes2/</a>.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->
            ]]>
        </content>
    </entry>
    <entry>
        <title>Monte Carlo Simulation (Python) Based on Fizell (2022)</title>
        <author>
            <name>Nikunj Bhalotia</name>
        </author>
        <link href="https://nb25877.github.io/monte-carlo-simulation-python-based-on-fizell-2022/"/>
        <id>https://nb25877.github.io/monte-carlo-simulation-python-based-on-fizell-2022/</id>

        <updated>2026-01-22T12:56:07+04:00</updated>
            <summary type="html">
                <![CDATA[
                    To understand how to model risks with high variance, I developed a Python script using numpy and pandas to run a Monte Carlo simulation. Instead of relying on a single "average" prediction for future risk exposure (e.g., potential financial loss), the simulation generated 1,000 random&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <!-- wp:paragraph -->
<p>To understand how to model risks with high variance, I developed a Python script using <code>numpy</code> and <code>pandas</code> to run a Monte Carlo simulation. Instead of relying on a single "average" prediction for future risk exposure (e.g., potential financial loss), the simulation generated <strong>1,000 random iterations</strong> based on historical volatility.</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li><strong>Key Concept Applied:</strong> The script used <code>norm.ppf</code> (Percent Point Function) to generate random variables within a specified mean and standard deviation, effectively simulating "black swan" events and best/worst-case scenarios.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Outcome:</strong> The output provided a probability distribution rather than a single number. This allowed me to state with <strong>95% confidence</strong> that the potential risk exposure would fall within a specific range, providing a far more defensible metric for stakeholders than a "High/Medium/Low" label.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>Description: This script simulates 1,000 potential outcomes for a financial risk scenario (e.g., cost of a data breach) using historical volatility data. It calculates the 95% confidence interval (Value at Risk).</p>
<!-- /wp:paragraph -->

<!-- wp:code {"tokenizedLines":[[["aW1wb3J0IG51bXB5IGFzIG5w"]],[["aW1wb3J0IHBhbmRhcyBhcyBwZA=="]],[["aW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdA=="]],[["ZnJvbSBzY2lweS5zdGF0cyBpbXBvcnQgbm9ybQ=="]],[[""]],[["IyAtLS0gQ09ORklHVVJBVElPTiAtLS0="]],[["IyBTY2VuYXJpbzogRXN0aW1hdGluZyBwb3RlbnRpYWwgZmluYW5jaWFsIGxvc3MgZnJvbSBhIHN1cHBseSBjaGFpbiBkaXNydXB0aW9u"]],[["IyBCYXNlZCBvbiBoaXN0b3JpY2FsIGRhdGEsIHdlIGFzc3VtZSBhIG5vcm1hbCBkaXN0cmlidXRpb24gb2YgZGFpbHkgbG9zcy4="]],[["c2ltdWxhdGlvbnMgPSAxMDAwICAgICAgICAgICMgTnVtYmVyIG9mIGl0ZXJhdGlvbnM="]],[["ZGF5c190b19mb3JlY2FzdCA9IDMwICAgICAgICMgRHVyYXRpb24gb2YgdGhlIHJpc2sgZXZlbnQ="]],[["YXZnX2RhaWx5X2xvc3MgPSA1MDAwICAgICAgICMgTWVhbiBkYWlseSBsb3NzIGluIEdCUA=="]],[["c3RkX2Rldl9sb3NzID0gMTUwMCAgICAgICAgICMgVm9sYXRpbGl0eSAoU3RhbmRhcmQgRGV2aWF0aW9uKQ=="]],[[""]],[["IyAtLS0gTU9OVEUgQ0FSTE8gU0lNVUxBVElPTiAtLS0="]],[["ZGVmIHJ1bl9zaW11bGF0aW9uKCk6"]],[["ICAgIHJlc3VsdHMgPSBbXQ=="]],[["ICAgIA=="]],[["ICAgIGZvciBpIGluIHJhbmdlKHNpbXVsYXRpb25zKTo="]],[["ICAgICAgICAjIEdlbmVyYXRlIHJhbmRvbSBkYWlseSBsb3NzZXMgYmFzZWQgb24gbm9ybWFsIGRpc3RyaWJ1dGlvbg=="]],[["ICAgICAgICAjIG5vcm0ucHBmIGNvbnZlcnRzIGEgcmFuZG9tIHBlcmNlbnRhZ2UgKDAtMSkgdG8gYSB2YWx1ZSBvbiB0aGUgZGlzdHJpYnV0aW9uIGN1cnZl"]],[["ICAgICAgICBkYWlseV9sb3NzZXMgPSBub3JtLnBwZihucC5yYW5kb20ucmFuZChkYXlzX3RvX2ZvcmVjYXN0KSwgbG9jPWF2Z19kYWlseV9sb3NzLCBzY2FsZT1zdGRfZGV2X2xvc3Mp"]],[["ICAgICAgICA="]],[["ICAgICAgICAjIEN1bXVsYXRpdmUgc3VtIG9mIGxvc3NlcyBmb3IgdGhpcyAzMC1kYXkgaXRlcmF0aW9u"]],[["ICAgICAgICB0b3RhbF9ldmVudF9jb3N0ID0gZGFpbHlfbG9zc2VzLnN1bSgp"]],[["ICAgICAgICByZXN1bHRzLmFwcGVuZCh0b3RhbF9ldmVudF9jb3N0KQ=="]],[["ICAgIA=="]],[["ICAgIHJldHVybiBucC5hcnJheShyZXN1bHRzKQ=="]],[[""]],[["IyAtLS0gRVhFQ1VUSU9OICYgQU5BTFlTSVMgLS0t"]],[["c2ltdWxhdGVkX2Nvc3RzID0gcnVuX3NpbXVsYXRpb24oKQ=="]],[[""]],[["IyBDYWxjdWxhdGUgS2V5IE1ldHJpY3M="]],[["bWVhbl9jb3N0ID0gbnAubWVhbihzaW11bGF0ZWRfY29zdHMp"]],[["d29yc3RfY2FzZSA9IG5wLnBlcmNlbnRpbGUoc2ltdWxhdGVkX2Nvc3RzLCA5NSkgIyA5NXRoIHBlcmNlbnRpbGUgKFZhbHVlIGF0IFJpc2sp"]],[["YmVzdF9jYXNlID0gbnAucGVyY2VudGlsZShzaW11bGF0ZWRfY29zdHMsIDUpICAgIyA1dGggcGVyY2VudGlsZQ=="]],[[""]],[["cHJpbnQoZiItLS0gUklTSyBGT1JFQ0FTVCAoMzAgREFZUykgLS0tIik="]],[["cHJpbnQoZiJNZWFuIEV4cGVjdGVkIENvc3Q6IMKje21lYW5fY29zdDosLjJmfSIp"]],[["cHJpbnQoZiI5NSUgQ29uZmlkZW5jZSBXb3JzdCBDYXNlOiDCo3t3b3JzdF9jYXNlOiwuMmZ9Iik="]],[["cHJpbnQoZiI1JSBDb25maWRlbmNlIEJlc3QgQ2FzZTogwqN7YmVzdF9jYXNlOiwuMmZ9Iik="]],[[""]],[["IyBPcHRpb25hbDogVmlzdWFsaXphdGlvbiBjb2RlIHdvdWxkIGdvIGhlcmU="]],[["IyBwbHQuaGlzdChzaW11bGF0ZWRfY29zdHMsIGJpbnM9NTAp"]]]} -->
<pre class="wp-block-code"><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import norm

# --- CONFIGURATION ---
# Scenario: Estimating potential financial loss from a supply chain disruption
# Based on historical data, we assume a normal distribution of daily loss.
simulations = 1000          # Number of iterations
days_to_forecast = 30       # Duration of the risk event
avg_daily_loss = 5000       # Mean daily loss in GBP
std_dev_loss = 1500         # Volatility (Standard Deviation)

# --- MONTE CARLO SIMULATION ---
def run_simulation():
    results = &#091;]
    
    for i in range(simulations):
        # Generate random daily losses based on normal distribution
        # norm.ppf converts a random percentage (0-1) to a value on the distribution curve
        daily_losses = norm.ppf(np.random.rand(days_to_forecast), loc=avg_daily_loss, scale=std_dev_loss)
        
        # Cumulative sum of losses for this 30-day iteration
        total_event_cost = daily_losses.sum()
        results.append(total_event_cost)
    
    return np.array(results)

# --- EXECUTION &#038; ANALYSIS ---
simulated_costs = run_simulation()

# Calculate Key Metrics
mean_cost = np.mean(simulated_costs)
worst_case = np.percentile(simulated_costs, 95) # 95th percentile (Value at Risk)
best_case = np.percentile(simulated_costs, 5)   # 5th percentile

print(f&#034;--- RISK FORECAST (30 DAYS) ---&#034;)
print(f&#034;Mean Expected Cost: £{mean_cost:,.2f}&#034;)
print(f&#034;95% Confidence Worst Case: £{worst_case:,.2f}&#034;)
print(f&#034;5% Confidence Best Case: £{best_case:,.2f}&#034;)

# Optional: Visualization code would go here
# plt.hist(simulated_costs, bins=50)</code></pre>
<!-- /wp:code -->

<!-- wp:heading -->
<h2 class="wp-block-heading">References:</h2>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Fizell, Z. (2022) <em>How to Create a Monte Carlo Simulation using Python</em>. Available at: <a href="https://towardsdatascience.com/how-to-create-a-monte-carlo-simulation-using-python-c24634a0978a/" target="_blank" rel="noreferrer noopener">https://towardsdatascience.com/how-to-create-a-monte-carlo-simulation-using-python-c24634a0978a/</a></p>
<!-- /wp:paragraph -->
            ]]>
        </content>
    </entry>
    <entry>
        <title>GDPR Case Study Analysis: Social Engineering Attack</title>
        <author>
            <name>Nikunj Bhalotia</name>
        </author>
        <link href="https://nb25877.github.io/gdpr-case-study-analysis-social-engineering-attack/"/>
        <id>https://nb25877.github.io/gdpr-case-study-analysis-social-engineering-attack/</id>

        <updated>2026-01-20T15:23:18+04:00</updated>
            <summary type="html">
                <![CDATA[
                    1. What is the specific aspect of GDPR that your case study addresses? This case addresses Article 32 (Security of Processing) and Article 5(1)(f) (Integrity and Confidentiality). The case involved a law firm where a staff member fell victim to a social engineering attack (phishing),&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <!-- wp:paragraph -->
<p><strong>1. What is the specific aspect of GDPR that your case study addresses?</strong> This case addresses <strong>Article 32 (Security of Processing)</strong> and <strong>Article 5(1)(f) (Integrity and Confidentiality)</strong>. The case involved a law firm where a staff member fell victim to a social engineering attack (phishing), allowing a malicious actor to install malware and defraud a client. The core GDPR issue was the data controller's failure to implement "appropriate technical and organisational measures" to ensure a level of security appropriate to the risk. Specifically, the firm relied on a cloud email service without enforcing basic industry-standard security settings, such as strong passwords or Multi-Factor Authentication (MFA).</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2. How was it resolved?</strong> Upon discovering the breach, the firm immediately commissioned a full forensic investigation to determine the root cause and extent of the compromise. Based on the findings, they implemented enhanced technical security measures (specifically enabling MFA) and conducted mandatory cyber security and data protection training for all staff. The DPC concluded the case by requesting updates on these implementations to ensure the risk of reoccurrence was mitigated.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>3. If this was your organisation, what steps would you take as an Information Security Manager to mitigate the issue?</strong> As an Information Security Manager, I would align our mitigation strategy with <strong>ISO/IEC 27001</strong> standards to ensure compliance with GDPR Article 32:</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li><strong>Implement Technical Controls (ISO 27001 A.9):</strong> I would mandate <strong>Multi-Factor Authentication (MFA)</strong> for all external access, particularly for cloud-based email services. Reliance on passwords alone is no longer considered "appropriate" for protecting sensitive client data.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Security Awareness Training (ISO 27001 A.7.2.2):</strong> I would implement a continuous "phishing simulation" program rather than one-off training. This tests employee resilience to social engineering in real-time.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Vendor Risk Management:</strong> Since the firm used a third-party cloud provider, I would review the shared responsibility model to ensure we are not assuming default settings are secure. We must configure the "tenant" side of the cloud service to meet our specific risk appetite.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>References</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li>Data Protection Commission (2023) <em>Case Studies: May 2018 – May 2023</em>. Available at: <a href="https://dataprotection.ie/sites/default/files/uploads/2024-08/DPC-CS-2023-EN-V2.pdf">https://dataprotection.ie/sites/default/files/uploads/2024-08/DPC-CS-2023-EN-V2.pdf</a></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->
            ]]>
        </content>
    </entry>
    <entry>
        <title>Threat Modelling for Industrial Cyber-Physical Systems</title>
        <author>
            <name>Nikunj Bhalotia</name>
        </author>
        <link href="https://nb25877.github.io/threat-modelling-for-industrial-cyber-physical-systems/"/>
        <id>https://nb25877.github.io/threat-modelling-for-industrial-cyber-physical-systems/</id>

        <updated>2026-01-20T15:02:47+04:00</updated>
            <summary type="html">
                <![CDATA[
                    Based on Jbair, M., Ahmad, B., Maple, C. and Harrison, R. (2022) 1. What are the key elements and interdependencies in a cyber-physical system that must be captured in a comprehensive threat model? A comprehensive threat model for Cyber-Physical Systems (CPS) must move beyond simple&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <!-- wp:paragraph -->
<p>Based on Jbair, M., Ahmad, B., Maple, C. and Harrison, R. (2022)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>1. What are the key elements and interdependencies in a cyber-physical system that must be captured in a comprehensive threat model?</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>A comprehensive threat model for Cyber-Physical Systems (CPS) must move beyond simple asset lists to capture the dynamic relationships between physical and digital components. Jbair et al. (2022) propose a data model that links ten critical parameters: Threat Actors (insider/outsider), Assets (classified by the Purdue Model), Vulnerabilities, Threats (using STRIDE), and Cyber-Attacks (using ICS ATT&amp;CK tactics).</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Critically, these elements are interdependent: a <strong>Threat Actor</strong> exploits a <strong>Vulnerability</strong> via specific <strong>Tactics, Techniques, and Procedures (TTPs)</strong> to manipulate an <strong>Asset</strong>. The accuracy of the risk analysis depends on capturing these links because the <strong>Attack Impact</strong> varies depending on the asset's physical function (e.g., a PLC at Level 1 has a higher safety impact than a workstation at Level 4). Failing to map these interdependencies results in a "siloed" view that misses cascading physical risks.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2. How can threat modelling help identify attack entry points and system vulnerabilities in cyber-physical energy systems?</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Threat modelling identifies entry points by mapping the "attack surface" exposed by the convergence of IT and OT (Operational Technology). By utilizing frameworks like ICS ATT&amp;CK, analysts can model specific attack trees—such as a "Man-in-the-Middle" attack on a PLC or a "Denial of Service" on an HMI. This structured approach moves beyond ad-hoc vulnerability scanning to identify complex attack paths where an adversary might pivot from a corporate network (Level 4) to control systems (Level 1).</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>However, a major challenge is that traditional threat modelling tools are often "static" and do not integrate with the engineering tools used to build CPS. Jbair et al. (2022) highlight that existing methodologies often lack the ability to determine risk severity or provide a roadmap for mitigation, making it difficult to justify security investments to engineering stakeholders.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>3. How can scenario-specific metrics and risk assessment methodologies be used to prioritise vulnerabilities?</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>To effectively prioritize vulnerabilities, organizations must move from qualitative "guesswork" to quantitative metrics. The paper proposes a formulaic approach where Risk (R) is the product of the Attack Vector (AV) and Attack Likelihood (AL) (R = AV \times AL).</p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li><strong>Attack Vector (AV):</strong> Calculated using the geometric mean of threat actor skills, threat exposure, and impact severity.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Attack Likelihood (AL):</strong> Derived from historical data of similar attacks in the sector (e.g., assessing if a specific malware strain is trending in the energy sector).</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>By applying these metrics to a <strong>Risk Heat Map</strong>, vulnerabilities can be classified from "Very Low" to "Very High." This allows security teams to automate the generation of <strong>Mitigation Controls</strong> (such as firmware monitoring or password enforcement) specifically for the highest-risk assets, ensuring that limited resources are targeted where they prevent the most significant physical and digital damage.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>References</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li>Jbair, M., Ahmad, B., Maple, C. and Harrison, R. (2022) ‘Threat modelling for industrial cyber physical systems in the era of smart manufacturing’, <em>Computers in Industry</em>, 137, p. 103611. Available at: <a href="https://doi.org/10.1016/j.compind.2022.103611" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/j.compind.2022.103611</a></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->
            ]]>
        </content>
    </entry>
    <entry>
        <title>The Role of AI in Risk Management</title>
        <author>
            <name>Nikunj Bhalotia</name>
        </author>
        <link href="https://nb25877.github.io/the-role-of-ai-in-risk-management/"/>
        <id>https://nb25877.github.io/the-role-of-ai-in-risk-management/</id>

        <updated>2026-01-19T16:58:46+04:00</updated>
            <summary type="html">
                <![CDATA[
                    Based on Kalogiannidis et al. (2024) 1. How does NLP improve the efficiency and accuracy of risk assessment processes? Natural Language Processing (NLP) fundamentally shifts risk assessment from a manual, labor-intensive process to an automated one capable of handling vast datasets. Kalogiannidis et al. (2024)&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <!-- wp:paragraph -->
<p>Based on Kalogiannidis et al. (2024)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>1. How does NLP improve the efficiency and accuracy of risk assessment processes?</strong> Natural Language Processing (NLP) fundamentally shifts risk assessment from a manual, labor-intensive process to an automated one capable of handling vast datasets. Kalogiannidis et al. (2024) highlight that over 80% of enterprise data is unstructured (e.g., text reports, social media), which traditional quantitative methods often struggle to process. By automating the analysis of this unstructured data, NLP significantly speeds up risk identification, finding supported by 70.2% of technology specialists. Furthermore, NLP reduces the human bias and error inherent in manual qualitative assessments, with 79.2% of respondents agreeing it improves identification accuracy.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2. In what ways can AI-powered data analytics enhance risk prediction and support business continuity?</strong> AI-powered analytics enables a transition from reactive to proactive risk management. Unlike traditional methods that rely on historical data and static risk factors, AI analytics can detect subtle patterns and anomalies in real-time streams. The study found that 71.5% of respondents agreed AI enhances the accuracy of predicting <em>potential</em> risks, rather than just reporting on past ones. Crucially, for business continuity, these tools allow for the rapid identification of "emerging risks" that have not yet materialised, with 93.5% of professionals noting that it supports a proactive approach.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>3. Why is it important for businesses to integrate multiple AI technologies, beyond just NLP?</strong> While NLP is effective for efficiency, the study’s regression analysis indicates its direct impact on <strong>business continuity</strong> is only moderate compared to other technologies. In contrast, the integration of AI into <strong>Incident Response Planning</strong> demonstrated the highest statistical impact on minimising business disruption (coefficient of 0.361). Therefore, a "comprehensive strategy" is required: NLP for data processing, predictive analytics for identifying emerging threats, and AI-driven incident response to enhance resilience during crises. Relying solely on one tool leaves gaps in the Risk Management Process.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>References</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul class="wp-block-list"><!-- wp:list-item -->
<li>Kalogiannidis, S., Kalfas, D., Papaevangelou, O., Giannarakis, G. and Chatzitheodoridis, F. (2024) ‘The Role of Artificial Intelligence Technology in Predictive Risk Assessment for Business Continuity: A Case Study of Greece’, <em>Risks</em>, 12(2), p. 19. Available at: <a href="https://doi.org/10.3390/risks12020019" target="_blank" rel="noreferrer noopener">https://doi.org/10.3390/risks12020019</a></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->
            ]]>
        </content>
    </entry>
</feed>
